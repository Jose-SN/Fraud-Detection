{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: seaborn in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: xgboost in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: lightgbm in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\data science\\learning\\ds7010 2425 (t2) dessertation\\fraud-detection\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy seaborn matplotlib scikit-learn joblib tqdm xgboost lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data_dir = \"./assets\"\n",
    "train_transaction_path = os.path.join(data_dir, \"train_transaction.csv\")\n",
    "train_identity_path = os.path.join(data_dir, \"train_identity.csv\")\n",
    "\n",
    "if not os.path.exists(train_transaction_path) or not os.path.exists(train_identity_path):\n",
    "    raise FileNotFoundError(\"One or both dataset files are missing. Please check the file paths.\")\n",
    "\n",
    "df_train = pd.read_csv(train_transaction_path)\n",
    "df_identity = pd.read_csv(train_identity_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge datasets\n",
    "df = df_train.merge(df_identity, on=\"TransactionID\", how=\"left\")\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(-999, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature selection\n",
    "features = [col for col in df.columns if col not in [\"TransactionID\", \"isFraud\"]]\n",
    "X = df[features]\n",
    "y = df[\"isFraud\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  25%|██▌       | 1/4 [02:08<06:25, 128.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    113975\n",
      "           1       0.76      0.14      0.24      4133\n",
      "\n",
      "    accuracy                           0.97    118108\n",
      "   macro avg       0.86      0.57      0.61    118108\n",
      "weighted avg       0.96      0.97      0.96    118108\n",
      "\n",
      "ROC AUC: 0.8357124959008557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  50%|█████     | 2/4 [04:55<05:02, 151.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113975\n",
      "           1       0.94      0.45      0.61      4133\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.96      0.72      0.80    118108\n",
      "weighted avg       0.98      0.98      0.98    118108\n",
      "\n",
      "ROC AUC: 0.9290264498366365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  75%|███████▌  | 3/4 [05:50<01:47, 107.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113975\n",
      "           1       0.90      0.50      0.64      4133\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.94      0.75      0.81    118108\n",
      "weighted avg       0.98      0.98      0.98    118108\n",
      "\n",
      "ROC AUC: 0.9409962474419986\n",
      "[LightGBM] [Info] Number of positive: 16530, number of negative: 455902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.083583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39130\n",
      "[LightGBM] [Info] Number of data points in the train set: 472432, number of used features: 431\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034989 -> initscore=-3.317101\n",
      "[LightGBM] [Info] Start training from score -3.317101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models: 100%|██████████| 4/4 [06:37<00:00, 99.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113975\n",
      "           1       0.88      0.44      0.59      4133\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.93      0.72      0.79    118108\n",
      "weighted avg       0.98      0.98      0.97    118108\n",
      "\n",
      "ROC AUC: 0.9278149553237716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Supervised Models with progress bar\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_roc_auc = 0\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved successfully!\n",
      "\n",
      "Best Model Test Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113975\n",
      "           1       0.90      0.50      0.64      4133\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.94      0.75      0.81    118108\n",
      "weighted avg       0.98      0.98      0.98    118108\n",
      "\n",
      "ROC AUC: 0.9409962474419986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, \"best_fraud_detection_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nBest model saved successfully!\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "print(\"\\nBest Model Test Evaluation:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_proba_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
